"""
Agent Runtime - Top-level orchestrator for multi-entry-point agents.

Manages agent lifecycle, coordinates concurrent execution streams,
and enforces runtime-wide safety guardrails.
"""

import asyncio
import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Callable, TYPE_CHECKING

from framework.graph.executor import ExecutionResult
from framework.runtime.shared_state import SharedStateManager
from framework.runtime.outcome_aggregator import OutcomeAggregator
from framework.runtime.event_bus import EventBus
from framework.runtime.execution_stream import ExecutionStream, EntryPointSpec
from framework.storage.concurrent import ConcurrentStorage

if TYPE_CHECKING:
    from framework.graph.edge import GraphSpec
    from framework.graph.goal import Goal
    from framework.llm.provider import LLMProvider, Tool

logger = logging.getLogger(__name__)


@dataclass
class AgentRuntimeConfig:
    """Configuration for AgentRuntime."""
    max_concurrent_executions: int = 100
    cache_ttl: float = 60.0
    batch_interval: float = 0.1
    max_history: int = 1000


class AgentRuntime:
    """
    Top-level runtime responsible for orchestrating agent execution.

    This layer intentionally owns:
    - Entry point registration
    - Execution stream lifecycle
    - Shared state & outcome aggregation
    - Runtime-wide safety guardrails (concurrency, idempotency)
    """

    def __init__(
        self,
        graph: "GraphSpec",
        goal: "Goal",
        storage_path: str | Path,
        llm: "LLMProvider | None" = None,
        tools: list["Tool"] | None = None,
        tool_executor: Callable | None = None,
        config: AgentRuntimeConfig | None = None,
    ):
        self.graph = graph
        self.goal = goal
        self._config = config or AgentRuntimeConfig()

        # Persistent storage
        self._storage = ConcurrentStorage(
            base_path=storage_path,
            cache_ttl=self._config.cache_ttl,
            batch_interval=self._config.batch_interval,
        )

        # Shared runtime components
        self._state_manager = SharedStateManager()
        self._event_bus = EventBus(max_history=self._config.max_history)
        self._outcome_aggregator = OutcomeAggregator(goal, self._event_bus)

        # LLM and tools
        self._llm = llm
        self._tools = tools or []
        self._tool_executor = tool_executor

        # Entry points and execution streams
        self._entry_points: dict[str, EntryPointSpec] = {}
        self._streams: dict[str, ExecutionStream] = {}

        # Runtime state
        self._running = False
        self._lock = asyncio.Lock()

    def register_entry_point(self, spec: EntryPointSpec) -> None:
        if self._running:
            raise RuntimeError("Cannot register entry points while runtime is running")

        if spec.id in self._entry_points:
            raise ValueError(f"Entry point '{spec.id}' already registered")

        if self.graph.get_node(spec.entry_node) is None:
            raise ValueError(f"Entry node '{spec.entry_node}' not found in graph")

        self._entry_points[spec.id] = spec
        logger.info(f"Registered entry point: {spec.id} -> {spec.entry_node}")

    async def start(self) -> None:
        if self._running:
            return

        async with self._lock:
            await self._storage.start()

            for ep_id, spec in self._entry_points.items():
                stream = ExecutionStream(
                    stream_id=ep_id,
                    entry_spec=spec,
                    graph=self.graph,
                    goal=self.goal,
                    state_manager=self._state_manager,
                    storage=self._storage,
                    outcome_aggregator=self._outcome_aggregator,
                    event_bus=self._event_bus,
                    llm=self._llm,
                    tools=self._tools,
                    tool_executor=self._tool_executor,
                )
                await stream.start()
                self._streams[ep_id] = stream

            self._running = True
            logger.info(f"AgentRuntime started with {len(self._streams)} streams")

    async def stop(self) -> None:
        if not self._running:
            return

        async with self._lock:
            for stream in self._streams.values():
                await stream.stop()

            self._streams.clear()
            await self._storage.stop()
            self._running = False
            logger.info("AgentRuntime stopped")

    async def trigger(
        self,
        entry_point_id: str,
        input_data: dict[str, Any],
        correlation_id: str | None = None,
        session_state: dict[str, Any] | None = None,
    ) -> str:
        """
        Trigger execution at a specific entry point.

        Runtime-level guardrails are enforced here (not inside ExecutionStream)
        to ensure global safety across all entry points before execution is scheduled.
        """
        if not self._running:
            raise RuntimeError("AgentRuntime is not running")

        stream = self._streams.get(entry_point_id)
        if stream is None:
            raise ValueError(f"Entry point '{entry_point_id}' not found")

        # --- RUNTIME GUARDRAIL: Max concurrent executions ---
        active_executions = getattr(stream, "active_executions", {})
        if len(active_executions) >= self._config.max_concurrent_executions:
            raise RuntimeError(
                f"Max concurrent executions reached for entry point '{entry_point_id}'"
            )

        # --- RUNTIME GUARDRAIL: Idempotency / duplicate execution prevention ---
        # correlation_id is treated as an idempotency key. If an execution with the same
        # correlation_id is already active, we avoid spawning a duplicate execution.
        if correlation_id and correlation_id in active_executions:
            logger.info(
                "Duplicate execution prevented for correlation_id=%s",
                correlation_id,
            )
            return correlation_id

        return await stream.execute(input_data, correlation_id, session_state)

    async def trigger_and_wait(
        self,
        entry_point_id: str,
        input_data: dict[str, Any],
        timeout: float | None = None,
        session_state: dict[str, Any] | None = None,
    ) -> ExecutionResult | None:
        exec_id = await self.trigger(entry_point_id, input_data, session_state=session_state)
        stream = self._streams[entry_point_id]
        return await stream.wait_for_completion(exec_id, timeout)

    # === QUERY OPERATIONS ===

    def get_entry_points(self) -> list[EntryPointSpec]:
        return list(self._entry_points.values())

    def get_stream(self, entry_point_id: str) -> ExecutionStream | None:
        return self._streams.get(entry_point_id)

    def get_execution_result(
        self,
        entry_point_id: str,
        execution_id: str,
    ) -> ExecutionResult | None:
        stream = self._streams.get(entry_point_id)
        if stream:
            return stream.get_result(execution_id)
        return None

    # === PROPERTIES ===

    @property
    def state_manager(self) -> SharedStateManager:
        return self._state_manager

    @property
    def event_bus(self) -> EventBus:
        return self._event_bus

    @property
    def outcome_aggregator(self) -> OutcomeAggregator:
        return self._outcome_aggregator

    @property
    def is_running(self) -> bool:
        return self._running


# === CONVENIENCE FACTORY ===

def create_agent_runtime(
    graph: "GraphSpec",
    goal: "Goal",
    storage_path: str | Path,
    entry_points: list[EntryPointSpec],
    llm: "LLMProvider | None" = None,
    tools: list["Tool"] | None = None,
    tool_executor: Callable | None = None,
    config: AgentRuntimeConfig | None = None,
) -> AgentRuntime:
    runtime = AgentRuntime(
        graph=graph,
        goal=goal,
        storage_path=storage_path,
        llm=llm,
        tools=tools,
        tool_executor=tool_executor,
        config=config,
    )

    for spec in entry_points:
        runtime.register_entry_point(spec)

    return runtime
